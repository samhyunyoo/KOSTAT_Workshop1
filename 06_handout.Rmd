---
title: | 
  | \includegraphics{logotip.pdf}
  |
  | KOSTAT-UNFPA Summer Seminar on Population
  | \vspace{1.5cm} \LARGE \emph{Workshop~1.~Demography in R}
  | \vspace{0.3cm} \huge \textbf{Day 6: Processing and visualizing South Korean fertility microdata}\vspace{0.6cm}
  | 
fontsize: 11pt
geometry: a4paper, twoside, left=2.5cm, right=2.5cm, top=2cm, bottom=2.8cm, headsep
  = 1.35cm, footskip = 1.6cm
output:
  pdf_document:
    number_sections: yes
  html_document2: default
  html_document:
    number_sections: yes
    toc: yes
  pdf_document2: default
  header-includes:
    - \usepackage{titling}
    - \usepackage{fancyhdr}
    - \pagestyle{fancy}
    - \fancyhead[LE]{\thepage~\qquad~KOSTAT-UNFPA Summer Seminar on Population}
    - \fancyhead[RE]{Workshop~1.~Demography in R}
    - \fancyhead[LO]{{Day 6: Processing and visualizing South Korean fertility microdata}}
    - \fancyhead[RO]{Tim Riffe\qquad~\thepage}
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\noindent\makebox[\textwidth][c]{
  \begin{minipage}[t]{0.8\textwidth}
    \centering
    \Large{Instructor: Tim Riffe \\ \texttt{tim.riffe@ehu.eus}}
   
    \vspace{.5cm}
    \Large{Assistants: \\ Jinyeon Jo: \texttt{jyjo43043@gmail.com} \\ Rustam Tursun-Zade: \texttt{rustam.tursunzade@gmail.com}}
  \end{minipage}
}


\vspace{0.8cm}
\begin{center}
\large{3 August 2022}
\end{center}
\vspace{0.8cm}


\tableofcontents

# Summary
Today we will exercise concepts previously presented to process and analyse births microdata delivered in *flat* files or *fixed-width* format. This means that data have no delimiters, but each column has a fixed character width. We will see that this data is easy and fast to read in bulk, and we will spend most of the session aggregating, merging with population data, and visualizing various kinds of results.

# Packages we'll use today

```{r, message = FALSE}

#install.packages("tidyverse")
## for standardized column names
#install.packages("janitor")
## for easy date handling
#install.packages("lubridate")
## for ridge plots
#install.packages("ggridges")
## read in data fast!
#install.packages("vroom")
## because country codes are a mess!
#install.packages("countrycode")
## we need this to install a package from github!
# install.packages("remotes")
library(tidyverse)
library(janitor)
library(lubridate)
library(ggridges)
library(vroom)
library(colorspace)

# for merging with population counts
library(countrycode)
library(remotes)
# run once!
# install_github("PPgp/wpp2022")
library(wpp2022)
```


# Fixed width microdata
KOSTAT kindly provided the birth data for the purpose of this workshop. Each observation in this data is an individual birth. These data contain 100% of registered births in Korea, and a selection of the many variables available from the original source. Typically these data are only accessible under restricted conditions after an application and evaluation. I will provide a link to a zipped folder containing the data to be used today, but these **should be deleted** when the workshop is over. If you require access to these data for research on Korean fertility, you should apply through the standard channels at KOSTAT. 

Note that data of this exact kind is openly available for a few countries around the world, including but not limited to [Spain](https://www.ine.es/dyngs/INEbase/en/operacion.htm?c=Estadistica_C&cid=1254736177007&menu=resultados&idp=1254735573002#!tabs-1254736195443) and the [United States](https://www.cdc.gov/nchs/data_access/vitalstatsonline.htm)

Initially, KOSTAT kindly provided the data to me already in comma-separated format, which we already know how to read into `R`. I put it (back?) in fixed-width format myself. If you're curious to see how I did that, and what I did to test today's code, you can refer to the supplementary handout `06_data_prep.pdf`. You will not be able to execute the `.Rmd` file because you do not have the original `.csv` files. 

## Download the data
Download the data (`Korea_births_fwf.zip`) using the link given in the `Google Doc` for the course (on the session day), and move it to the `Data` folder of the workshop project. Once there, you can unzip the file from `R` like so:

```{r}
unzip("Data/Korea_births_fwf.zip", 
      # in case this isn't the first time
      overwrite = TRUE,
      exdir = "Data")
```
A new folder will be created: `Data/Korea_births_fwf`, which contains one file each for years 2000-2020. Files follow the naming convention `kbyyyy.txt`, where `yyyy` is the given year. You can open one of these in a text editor and have a look. For some columns, in some places it seems obvious what a variable is, but in general we see that some sort of parsing is needed in order to get this data into any program.

Here is a glimpse of the first several rows of the first fixed-width file:
\begin{verbatim}
2000   2000   1   1      12000   1 36   34   35 2.36  
2000   2000   1   1      12000   1 27   27   37 2.4   
2000   2000   1   1      12000   1 25   25   37 2.9   
2000   2000   1   1      12000   1 29   26   38 3.49  
2000   2000   1   1      12000   1 31   24   39 3.16  
2000   2000   1   1      12000   1 35   29   39 3.24  
2000   2000   1   1      12000   1 29   28   40 3.05  
2000   2000   1   1      12000   1 34   27   40 3.3  
\end{verbatim}



## Read the data into `R`

The `readr` package has a nice function `read_fwf()` to read in this sort of data. It requires you to either know the the starting position and width of each column (in terms of character positions), or the starting and stopping positions. If all you know are the widths of each column, then you must know these for each column in the data. When we read the data in, white space is automatically eliminated, and `R` guesses the data type for each column (which we can of course override if we want). Look at the help file (`?read_fwf`) for examples of all the different ways to read in fixed-width data.

### Create metadata
In this case, you can read in the metadata directly from a `.csv` file in github like so:
```{r, include = FALSE}
widths <- read_csv("Data/Korea_births_fwf_metadata.csv")
```

```{r, eval = FALSE}
# cutting url in two pieces because it's so long it won't fit on a page!
url_base <- "https://raw.githubusercontent.com/timriffe/KOSTAT_Workshop1/"
url_end  <- "master/Data/Korea_births_fwf_metadata.csv"
my_url   <- paste0(url_base, url_end)
widths <- read_csv(my_url,
                   # suppress messages
                   show_col_types = FALSE)
```
Let's have a look:
```{r}
widths
```

From this we see we have 11 columns, and we know the width of each. These should add up to the full width of a given line in the data. To use `read_fwf()`, we just need to convert this into some standard *begin-end* specifications, like so:

```{r}
specs <-
  fwf_widths(widths = widths$width,
             col_names = widths$colname)
specs
```
This translation from widths should be pretty straightforward. Sometimes your metadata is already delivered just like this, with start and stop positions, ideally in a spreadsheet, but sometimes unfortunately in a `.pdf`. Even so, it's good to create this `R` object using one of the helper functions listed when you type `?fwf_widths` to ensure that it follows the standards anticipated.

Note: *begin-end* specification is the most flexible. Sometimes data of this kind is very large and you don't need all the columns. Using this specification, you could include only those columns that you need, as so save some of your machine memory :-)

### Trial for one file

Let's see what we get with just one file. With this we can eyeball the column classes and explicitly specify these when we read them all in at once.
```{r, message = FALSE}
# read_fwf() comes from readr package
data_in <- read_fwf("Data/Korea_births_fwf/kb2000.txt",
                    col_positions = specs)
data_in
```

* NOTE: in practice, file formats change every few years. You might start with some metadata for ranges of years, which then switches, or you may have unique metadata for each year. In that case, you'd need to repeat the above as much as needed, and it's a bit more laborious. But you'll of course still want to write the code to do it, which will make the task repeatable.

### Read and merge all files using `vroom`

To read in the file, use `vroom_fwf()`, and feed our `specs` object to the `col_positions` argument. Here I explicitly state what the data type should be for each column using a shorthand: `i` stands for integer, and `d` stands for double (data with decimals). If you omit this step, then `Birth weight` will be interpreted as character. That's not really a problem, you could coerce it back to double using `mutate(`Birth weight` = as.double(`Birth weight`))`. We use `vroom` because it's blazing fast compared to other options. In our case, we have identically formatted files in a folder, and it just reads them all in at once.
```{r}
rm(data_in) # remove earlier test file from memory
# a vector of file paths:
kb_folder <- "Data/Korea_births_fwf"
files <- file.path(kb_folder,
                   dir(kb_folder))

# read and merge, very fast :-)
KB     <- vroom_fwf(files,
                    col_positions = specs,
                    col_types = "iiiiiiidddd")
str(KB)
```

It appears there were 9369102 births registered in South Korea between the years 2000 and 2020, inclusive.

## tidy the data some

First, the names are a bit awkward to type out in back-tics whenever we want to refer to a variable in code. I'd prefer to type `mother_detailed_age` rather than `r '\x60(Mother) detailed age\x60'`. Even better would be `mo_age`! Also, in various places we'll want time coded as a date. For this we can use a helper function from the `lubridate` package, `ymd()`, you can give it strings like `"2000-01-01"` or `"2000 01 01"` or `"2000 1 1"`, and it'll interpret them properly and coerce to date data type. See also `dmy()`, `mdy()`, `as_date()`, and others.

```{r, message = FALSE}
KB <-
  KB %>% 
  clean_names() %>% 
  # date useful for plotting
  mutate(date = ymd(paste(year_of_birth,
                   month_of_birth,
                   "01")))
```


Check values to infer missing codes: no missing month or year of birth variables; 999 used for missing ages. `floor()` is used to *round down* age to the nearest integer, which is the way demographers most commonly handle age.
```{r}
KB %>% pull(month_of_birth) %>% table()
KB %>% pull(year_of_birth) %>% table()
# code 999 is unstated age
KB %>% pull(father_detailed_age) %>% floor() %>% table()
KB %>% pull(mother_detailed_age) %>% floor() %>% table()
```

For some of our explorations, we can throw out unknown ages, and for others we should redistribute them. When we redistribute unknown ages, this usually follows tabulation rather than precedes it. 

### Convert age to integer and rename

For the sake of simplified typing, I think we'd prefer to have `fa_age` rather than `father_detailed_age`. Let's rename some columns, and also select only those that we need (since the data are somewhat big) using `select()`. Also for ages, we won't need anything more than integer precision, and, we can replace `999` codes with `NA` (for this we use a helper function `na_if()`. We prefer to use actual `NA` values so that they're easier to remember and detect whenever doing arithmetic things with age itself. 

```{r}
KB <- 
  KB %>% 
  # rename and select columns
  select(date,
         month = month_of_birth,
         year = year_of_birth,
         fa_age = father_detailed_age,
         mo_age = mother_detailed_age,
         sex,
         p_weeks = no_of_weeks_of_pregnancy,
         birth_weight) %>% 
  # coerce age to integer 
  mutate(mo_age = floor(mo_age),
         fa_age = floor(fa_age),
         # replace 999 with NA
         mo_age = na_if(mo_age, 999),
         fa_age = na_if(fa_age, 999))
head(KB)
```

## Explore seasonality

We are going to explore seasonality not in the strict sense being used in many excess mortality methods: Here we're not going to *separate* seasonality from a smooth medium-term trend, we'll just eyeball it atop the trend. 

### seasonality of births by month
Let's get a sense of how seasonal births are. This will happen in two steps:
1. Aggregate the data by year, month; use the `n()` function inside `summarize()` to count rows
2. Create a date variable 
3. plot the result

```{r, message = FALSE}
month_totals <-
  KB %>% 
  group_by(date, month) %>% 
  summarize(births = n(), 
            .groups = "drop")  
```

In plotting, we notice that births tend to have a January spike:
```{r}
month_totals %>%   
  ggplot(aes(x = date, y = births)) +
  geom_line() +
  # more honest but too much visual vibration IMO:
  # geom_step() 
  
  # put a red dot on each January value
  geom_point(data = month_totals %>% 
               filter(month == 1), 
             color = "red") +
  geom_point(data = month_totals %>% 
               filter(month == 12), 
             color = "blue") +
  labs(title = "What explains the discontinuity between December and January?") +
  theme_minimal()
```
I presume some of the Korean workshop participants know what is going on. I, however, do not. Is it that conceptions (natural or assisted) are equally seasonal? Although conceptions are surely also seasonal, they cannot produce a discontinuity like this because there is a *smooth*ish distribution of gestation durations that prevents it. Are gestational periods being shortened / lengthened in order to achieve this result? Is it low-key fraud to give children a better position within their cohort? Are December due-dates more likely to be aborted? I unfortunately did not request variables for cesarean deliveries, nor for whether a conception was assisted, or for birth parity. Further, we lack in these data any conceptions that did not come to term.

#### Exercise (3 min) 
Take 3-4 minutes to calculate this time series separately for boy births and girl births, and plot the two lines, mapping color to sex. Is one series more seasonal than the other?

```{r, include = FALSE}
KB %>% 
  group_by(date, month, sex) %>% 
  summarize(births = n(), 
            .groups = "drop") %>% 
  mutate(sex = if_else(sex == 1, "boys","girls")) %>% 
  ggplot(aes(x = date, y = births, color = sex)) +
  scale_color_manual(values = c(boys = "#3f9655",girls = "#6f3f96"))+
  geom_line() +
  labs(title = "Both boys and girls seem to have the same discontinuity") +
  theme_minimal()
```


### seasonality of sex ratio

Does the sex ratio at birth have any regular seasonality? We'd expect it to be more erratic, and it does seem to be this way. Higher values means more boys. I don't see a consistent mapping to the December-January discontinuity we saw before.
```{r}
monthly_sr <-
 KB %>% 
  group_by(date, month, sex) %>% 
  summarize(births = n(), 
            .groups = "drop") %>% 
  pivot_wider(names_from = sex, 
              values_from = births) %>% 
  mutate(sex_ratio = `1`/`2`) 

monthly_sr %>% 
  ggplot(aes(x = date, y = sex_ratio)) +
  geom_line() +
  geom_point(data = monthly_sr %>% filter(month == 1), 
             color="red") +
  geom_point(data = monthly_sr %>% filter(month == 12), 
             color="blue") +
  labs(y = "sex ratio at birth") +
  theme_minimal()
```

### seasonality of conceptions

What would a time-series of *conceptions resulting in live births* look like? This unfortunately won't be the same as an unconditional time series of conceptions, that's just the nature of live-birth data. For the case of the USA and Spanish data linked above, one could join with data on pregnancies or fetal deaths to get a closer-to-complete time series of conceptions. Caveats (that is, conditioning) aside, let's get down to pragmatic programming.

We have a variable `p_weeks`. This is in weeks, but we only have month-resolution for births, ouch. Let's figure out a way to hack this so we can make the desired time-series. My hackish approach will be to assume that a birth happens on the 15th day of the month, and to subtract whole weeks of pregnancy from this, ergo: `date_conception_approx = date - p_weeks * 7 + 15`. The resulting dates are going to be scattered, but we can group these back into months using the `month()` helper function (give it a date, it returns a month integer, see also `day()` and `year()`). Once we get the (approximate) month of conception, we can aggregate, and once again recreate a "first of the month" date column for purposes of plotting:

```{r}
conceptions_month <-
  KB %>% 
  mutate(date_conception_approx = date - p_weeks * 7 + 15,
         year = year(date_conception_approx),
         month_conception_approx = month(date_conception_approx)) %>% 
  group_by(year, month_conception_approx) %>% 
  summarize(conceptions = n(), 
            .groups = "drop") %>% 
  mutate(date_for_plotting = ymd(paste(year,
                          month_conception_approx,
                          "01"))) 
```

Plot it, highlighting both peaks and valleys
```{r, warning = FALSE}
conceptions_month %>% 
  ggplot(aes(x = date_for_plotting, y = conceptions )) +
  geom_line() +
  geom_point(data = conceptions_month %>% filter(month_conception_approx %in% c(4,6)),
             color = "red") +
  geom_point(data = conceptions_month %>% filter(month_conception_approx %in% c(2,9)),
             color = "blue") +
  labs(title = "Live births by approx conception month",
       subtitle = 
       "April - June might be popular conception months;
September - February not so much?") +
  xlim(ymd("1999-08-01"),ymd("2020-03-01")) +
  labs(x = "Conception time (approx)", y = "Births") +
  theme_minimal()
```

## Exploring distributions

### Gestation weeks distributions
How does the distribution of live births by weeks of gestation change as a function of mothers' age? We use the moulo `%%` operator to help aggregate to 5-year age groups. Observe the behavior:
```{r}
age <- 0:20
age
# this we can aggregate on, get it?
age - age %% 5
```

```{r}

density_by_mother_age <-
  KB %>% 
  filter(mo_age < 70,
         # why are some `p_weeks` equal to 0?
         p_weeks > 0) %>% 
  # note the %% (modulo) trick.
  mutate(mo_age5 = mo_age - mo_age %% 5) %>% 
  group_by(mo_age5, p_weeks) %>% 
  summarize(n = n(), .groups = "drop") %>%
  ungroup() %>% 
  group_by(mo_age5) %>% 
  mutate(dens = n / sum(n) ) 
```

Plot it as a ridge plot!
```{r}
density_by_mother_age %>% 
  ggplot(aes(x = p_weeks, y = factor(mo_age5),height=dens)) +
  geom_ridgeline(scale = 5, alpha = .5) +
  xlim(30,46) +
  labs(y = "mother age group",
       x = "weeks of gestation",
       title = "How does the distribution of gestation time vary by mother age?") +
  theme_minimal()
```

#### Exercise (5 min)
Repeat this ridge plot, except use fathers' age in 5-year age groups. Does the distribution seem to change its shape more by fathers' age or mothers' age?

```{r, include = FALSE}
KB %>% 
  filter(fa_age < 70,
         fa_age >= 15,
         # why are some `p_weeks` equal to 0?
         p_weeks > 0) %>% 
  # note the %% (modulo) trick.
  mutate(fa_age5 = fa_age - fa_age %% 5) %>% 
  group_by(fa_age5, p_weeks) %>% 
  summarize(n = n(), .groups = "drop") %>%
  ungroup() %>% 
  group_by(fa_age5) %>% 
  mutate(dens = n / sum(n) ) %>% 
  ggplot(aes(x = p_weeks, y = factor(fa_age5), height = dens)) +
  geom_ridgeline(scale = 5, alpha = .5) +
  xlim(30,46) +
  labs(y = "father age group",
       x = "weeks of gestation",
       title = "How does the distribution of gestation time vary by father age?") +
  theme_minimal()
```


#### Exercise (7 min)
again, throwing out unknown mother and father ages, calculate a new variable called `age_diff` (father age minus mother age). Use `case_when()` to categorize age differences into 3 bins: 
1. `age_diff > 2`
2. `between(age_diff,2,-2)`
3. `age_diff < -2`
Again, recreate the first ridgeplot (using `mother_age5`), and map `fill` color to your new 3-category `age_diff`. 

```{r, include = FALSE}
  KB %>% 
  filter(mo_age < 60,
         fa_age < 70,
         # why are some `p_weeks` equal to 0?
         p_weeks > 0) %>% 
  mutate(mo_age5 = mo_age - mo_age %% 5,
         age_diff = fa_age - mo_age,
         age_diff = case_when(
           age_diff > 2 ~ "father > mother",
           age_diff < -2 ~ "mother < father",
           TRUE ~ "approx equal"
         )) %>% 
  group_by(age_diff, mo_age5, p_weeks) %>% 
  summarize(n = n(), .groups = "drop") %>%
  ungroup() %>% 
  group_by(mo_age5, age_diff) %>% 
  mutate(dens = n / sum(n) )  %>% 
  
  ggplot(aes(x = p_weeks, 
             y = factor(mo_age5),
             height=dens,
             fill = age_diff)) +
  geom_ridgeline(scale = 3,
                           alpha = .3) +
  xlim(30,46) +
  labs(x = "weeks of gestation",
       y = "mother age group",
       fill = "age differences",
       title = "Age differences between parents don't seem to make a big difference
in the gestation time distribution",
subtitle = "Except maybe in the oldest and youngest ages") +
  theme_minimal()
```

### Age distributions

Now we'll modify a bit the previous exercise (sorry for the giveaway) in order to reveal that these virtually identical distributions are nonetheless on quite different scales, and that these relative scales shift over age. In this case, one could try to scale within mother age only as a different density:

```{r}
density_by_mother_age_diff2 <-
  KB %>% 
  filter(mo_age < 60,
         fa_age < 70,
         fa_age >= 15,
         # why are some `no_of_weeks_of_pregnancy` equal to 0?
         p_weeks > 0) %>% 
  mutate(mo_age5 = mo_age - mo_age %% 5,
         age_diff = fa_age - mo_age,
         age_diff = case_when(
           age_diff > 2 ~ "father > mother",
           age_diff < -2 ~ "mother < father",
           TRUE ~ "approx equal"
         )) %>% 
  group_by(age_diff, mo_age5, p_weeks) %>% 
  summarize(n = n(), .groups = "drop") %>%
  ungroup() %>% 
  group_by(mo_age5) %>% 
  mutate(dens = n / sum(n) ) 
```
Plot it. This makes clearer that for younger mothers, it's more common to have older fathers, but as mother ages increase, it becomes more prevalent to have younger fathers.
```{r}
density_by_mother_age_diff2 %>% 
  ggplot(aes(x = p_weeks, 
             y = factor(mo_age5),
             fill = age_diff,
             height = dens)) +
  ggridges::geom_ridgeline(scale = 5,
                           alpha = .3) +
  xlim(30,46) +
  theme_minimal()
```

But then, since the distribution shapes don't differ except in the top category, we really should simplify the display to show the *shifting age differences* balance.

```{r}
age_diff_density_by_mother_age <-
  KB %>% 
  filter(mo_age < 60,
         fa_age < 75) %>% 
  mutate(mo_age5 = mo_age - mo_age %% 5,
         age_diff = fa_age - mo_age,
         # 2-year diff bins, why not?
         age_diff = age_diff - age_diff %% 2) %>% 
  group_by(age_diff, mo_age5) %>% 
  summarize(n = n(), .groups = "drop") %>%
  group_by(mo_age5) %>% 
  mutate(dens = n / sum(n) ) 
```

This density gets the shifting age differences over better. Remember each level is scaled to sum to 1, so this isn't a direct translation of a 2d age plot, which would give the full 2d density.
```{r}
age_diff_density_by_mother_age %>% 
  ggplot(aes(x = age_diff, 
             y = factor(mo_age5),
              height=dens)) +
  ggridges::geom_ridgeline(scale = 5,
                           alpha = .3) +
  coord_fixed(ratio= 5)+
  xlim(-15,15) +
  labs(y = "mother age group",
       x = "age difference") +
  theme_minimal()
```

Here's that density plot (mother age by father age)

```{r}
my_breaks = c(0,1,10,100,1000,10000)
 KB %>% 
  filter(mo_age < 60,
         fa_age < 75) %>% 
  group_by(mo_age,
           fa_age) %>% 
  summarize(n = n(), .groups = "drop") %>% 
  ggplot(aes(x = mo_age,
             y = fa_age,
             fill = n)) +
  geom_tile() +
  coord_equal() +
  scale_fill_continuous_sequential("PurpOr",
                                   trans = "log",
                                   breaks = my_breaks)+
  geom_abline(slope = 1,
              intercept = 0, 
              color = "#22222250") +
  labs(x = "mother age",
       y = "father age",
       title = "Birth distribution by mother and father age",
       subtitle = "years 2000-2020, South Korea") +
  theme_minimal()
```

This picture gives the overall count density, but really, we'd like to see this on a rate scale since cohorts of presumably varying size have passed through the data. Rates give a better reflection of a conditional intensity: conditional on there being people exposed. This is easy to do for mother's age-specific exposure or fathers' age-specific exposure separately, but to consider exposures jointly is a conundrum of formal demography (the *two-sex problem*). 

#### Exercise (5 min)
Aggregate years into wide periods (5-years, say), creating a new variable called `period` with values such as `"2000-2004"`, and so on (remember `case_when()`). Then recreate the above surface-plot, but *faceted* on `period`. Do you note any changes in this bivariate distribution?

#### Exercise: (5 min)
1. Make a surface plot of `p_weeks` by `birth_weight`
2. Can you visually assess somehow if the relationship is stable over mothers' age?

```{r}
KB %>% 
  pull(birth_weight) %>% hist()

KB %>% 
  filter(p_weeks > 0) %>% 
  mutate(birth_weight = birth_weight - birth_weight %% .1 + 0.05 ) %>% 
  group_by(p_weeks, birth_weight) %>% 
  summarize(n = n(), .groups = "drop") %>% 
  ggplot(aes(x = p_weeks,
             y = birth_weight))+
  geom_density2d_filled()
```


Question:
Is birth-weight seasonal to any extent? What about age differences of parents? What strange questions? But see how straightforward it is to ask them of the data!

```{r}
seasonal_birth_weight <-
KB %>% 
  group_by(date) %>% 
  summarize(avg_birth_weight = mean(birth_weight),
            med_birth_weight = median(birth_weight),
            sd_birth_weight = sd(birth_weight)) %>% 
  pivot_longer(avg_birth_weight:sd_birth_weight,
               names_to = "measure",
               values_to = "value")
```

Well, maybe not so odd, at first glance birth weight has a seasonal mean. Recall this is the mean of a rather wide distribution.
```{r}
seasonal_birth_weight %>% 
  filter(measure != "sd_birth_weight") %>% 
  ggplot(aes(x = date,
             y = value,
             color = measure,
             group = measure)) +
  geom_line() +
  labs(title = "Birth weight is seasonal",
       subtitle = "Winter babies are fatter?",
       y = "mean and median birth weights") +
  theme_minimal()
```

Now this is just fascinating to me. The recent decoupling of the mean and median of `birth_weight` must be due to tail action. I wonder: how has the distribution changed over the years? Again, it's the shape that's interesting, so we can scale within periods. 

```{r, warning = FALSE}
KB %>% 
  mutate(year2 = year - year %% 2,
         birth_weight = birth_weight - birth_weight %% .1) %>% 
  group_by(year2, birth_weight) %>% 
  summarize(n = n(), .groups = "drop") %>% 
  group_by(year2) %>% 
  mutate(dens = n / sum(n)) %>% 
  ggplot(aes(x = birth_weight,
             y = dens,
             color = year2,
             group = year2)) +
  geom_line() +
  # ggplot(aes(x = birth_weight, y = factor(year2), height=dens)) +
  # geom_ridgeline(scale = 8, fill = "red",alpha=.5) + 
  xlim(1.8,4.2) +
  labs(x = "birth weight (kg)",
       y = "distribution",
       fill = "year",
       title = "Birth weight distribution by 2-year periods",
       caption = "Possibly different digit precision by year?") +
  theme_minimal() 
  
```

# Prepare merge with population 

We will use population denominators from the recent `wpp2022` `R` package. This package is on github because it's big, and CRAN doesn't like big data packages. Earlier versions of WPP data packages weren't as big because they were in 5-year age groups and periods.

When we calculate exposures, we should take into account this notice from the github `README`:

> Caution: All annual population datasets are considered to depict population to December 31 of each year.

So, 2000 means 31 December, 2000, and we should adjust our exposure approximation accordingly. Actually, I'll just redefine `year` as `year + 1`. 

```{r}
data(pop1dt)
str(popAge1dt)
# what is South Korea's code in the UN system?
countrycode("South Korea", origin = "country.name.en", destination = "un")
# check once again:
countrycode(410, origin = "un", destination = "iso3c")
# see how the countrycode package is cool?

E <- 
  popAge1dt %>% 
  filter(country_code == 410,
         year %in% 1999:2020) %>% 
  # scale up pop
  mutate(popM = popM * 1000,
         popF = popF * 1000,
         # bring back to Jan 1
         year = year + 1) %>% 
  select(-pop) %>% 
  rename(m = popM,
         f = popF) %>% 
  pivot_longer(c(m,f),
               names_to = "sex",
               values_to = "pop") %>% 
  arrange(sex, age, year) %>% 
  group_by(sex, age) %>% 
  mutate(expos = (pop + lead(pop)) / 2) %>% 
  ungroup() %>% 
  filter(!is.na(expos))
```

Considerations for joining:
In the births data, father age and mother age necessarily cross-categorized, but we have no obvious way of cross-categorizing population counts. There might be nice tricks we could do to approximate *joint* exposure, but at first I think we best concentrate on either getting female or male fertility rates. In this case, we should tabulate births by year and mother age, and redistribute unknown ages. 

