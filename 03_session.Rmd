---
title: "Session 3 notes"
author: "Tim Riffe"
date: "2022-07-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Review of tidyverse data processing function

`filter()` is for rows, you need to know logical expressions
`select()` is for columns, there are helper functions, like `contains()` or you can give ranges.
`group_by()` whenever you want to do things separately in your data, don't forget to `ungroup()` when you're done!
`mutate()` for creating or modifying columns
`summarize()` is for making aggregations of various kinds, usually done together with `group_by()`.

### we didn't yet cover:
`pivot_longer()` for gathering columns and stacking them.
`pivot_wider()` for spreading out the contents of a column over a new range of columns.

## Get the data

We went to github, clicked on the file name once, then clicked `Download` and put it in the `Data` folder.

## Read in the data

We use the `readxl` package to exract tables from spreadsheets.
```{r, message = FALSE, warning = FALSE}
library(tidyverse)
# install.package("readxl")
library(readxl)
```

```{r}
B <- read_excel(path = "Data/demo_fasec.xlsx",
                range = "A10:H158",
                na = ":")
View(B)
# ?read_excel
```

## Step 1 reshape to long

Pivot wider is for stacking columns. It usually results in fewer columns and always results in more rows. In our case, we're collecting 6 columns, each with 148 values, so that resulting data object shoul should have `148 * 6 = 888` rows. And we want TWO new columns, births and year. We create these names using `names_to` and `values_to`. There are flexible ways of specifying which columns to collect.

```{r}
B <-
  B %>% 
  pivot_longer(cols = `2011`:`2016`,
               # cols = 3:8
               # cols = 3:ncol(.)
               names_to = "year",
               values_to = "births")
```

### Time out for `pivot_wider()`

Usage of `pivot_wider()` is a bit simpler: you just need to tell it which columns to spread out. One becomes the names (should be limited categories) (`names_from`), and the other is what to put in the cells `values_from`.
```{r}
B %>% 
  pivot_wider(names_from = "year",
              values_from = "births")
```

## Step 2 simplify column names

We could use `select()`, but you can't leave any columns out.
Instead we use `rename()` because it requires less typing, and does just this one thing. To be explicit we rename using `to = from`.
```{r}
# B %>% 
#   select(age = AGE,
#          country = `GEO/TIME`,
#          year,
#          births)
B <-
  B %>% 
  rename(age = AGE,
         country =`GEO/TIME`)
```

## Step 3 rescale births

We usually respect stated totals by rescaling observed distributions to be constrained to the stated total. We do this knowing that possibly the age (or whatever) distribution of births of unknown maternal age might not be the same. So this operation might induce bias if it is both the case that the fraction of births in unknown ages is high and the distributions is different.

$$  \hat{B_x} = \frac{B_x}{\sum{B_x}} \cdot T $$

```{r}
B <- 
  B %>% 
  # filter(country == "Belgium",
  #        year == 2015) %>% 
  group_by(country, year) %>% 
  mutate(total = births[age == "Total"]) %>% 
  filter(! age %in% c("Total", "Unknown")) %>% 
  mutate(#dist = births / sum(births),
         #births = dist * total
         births_hat = births / sum(births) * total)

# quick check: are we being overly manipulative here or not?
# conclusion: no, worst case is 1% unknown.
B %>% 
  group_by(country, year) %>% 
  summarize(total = births[age == "Total"],
            unk = births[age == "Unknown"]) %>% 
  ungroup() %>% 
  mutate(badness = unk / total * 100)
# births / sum(births) * total
```

## Step 4 convert age to integer

I mentioned some other ways we could pick out the age numbers from the strings. The function `parse_number()`, which loaded with the tidyverse is usually the cheapest option.
```{r}
B %>% pull(age) %>% unique()
B <-
  B %>% 
  mutate(age = parse_number(age))
```

## put it all together

```{r}
B <-
  # 1. read in from range we got from visual inspection,
  # explicitly specify the NA character
  read_excel(path = "Data/demo_fasec.xlsx",
             range = "A10:H158",
             na = ":") %>% 
  
  # 2. then stack the columns for births by year,
  # columns "2011" until "2016" are removed, 
  # and year and births are created
  pivot_longer(cols = `2011`:`2016`,
               names_to = "year",
               values_to = "births") %>% 
  
  # 3. clean the names
  rename(age = AGE,
         country =`GEO/TIME`) %>% 
  
  # 4. rescale to totals within unique subsets of year and country
  group_by(country, year) %>% 
  
  # bring out total to a new column
  mutate(total = births[age == "Total"]) %>% 
  
  # throw out these rows, otherwise they contaminate the distribution
  filter(! age %in% c("Total", "Unknown")) %>% 
  
  # we assume unknowns follow same distribution as knowns
  mutate(births_hat = births / sum(births) * total) %>% 
  ungroup() %>% 
  
  # 5. clean age column
  mutate(age = parse_number(age))
  
```

### Exercise (not fully defined, beyond this workshop)

When we redistribute to sum to the stated total, in this case, we are ALSO redistributing some births that happen in the tails (< 15, >= 50), and that is bad. If we wanted to do this more rigorously we would 
1. calculate the total tail size (total - (15:49 + unkown))
2. convert observed births to rates
3. extrapolate using a model to cover a wider age range
4. convert back to counts.
5. rescale to total

## Now let's get exposures


### 1. read in population

This works just as before
```{r}
P <- 
  read_excel(path = "Data/demo_pjan.xlsx",
             range = "A10:CZ510",
             na = ":")

```

### 2. `pivot_longer()` for age

reshape to longer, creating new columns for age and pop.
```{r}
P <-
  P %>% 
  pivot_longer(#cols = 3:104,
               `Less than 1 year`:Unknown,
               names_to = "age",
               values_to = "pop")
# P %>% colnames()
```

### 3. remove the NA rows

We also do some checks in case some subsets have unexpected missings
```{r}
P <- 
  P %>% 
  filter(!is.na(pop))
# check subset sizes; some close out at 85+ or 90+
# P %>% 
#   group_by(TIME, `GEO/AGE`) %>% 
#   summarize(n = n()) %>% 
#   View()
# 
# P %>% 
#   filter(`GEO/AGE` == "Albania",
#          TIME == 2012) %>% 
#   View()
```

### 4. rename columns where helpful

```{r}
P <- 
  P %>% 
  rename(year = TIME,
         country = `GEO/AGE`)
```

### 5. redisitribute unknowns

$$ \hat{P_x} = P_x + \frac{P_x}{\sum P_x} * P_{Unk} $$

```{r}
P <- 
  P %>% 
  group_by(country, year) %>% 
  mutate(unk = pop[age == "Unknown"]) %>% 
  filter(age != "Unknown") %>% 
  mutate(pop_hat = pop + pop / sum(pop) * unk) %>% 
  ungroup() 

  # eyeball check to make sure we actually did something:
  # filter(country == "North Macedonia") %>% pull(pop_hat)

  # just checking in case we need to be more rigourous,
  # do we have missing unknown ages? NO
  # ungroup() %>% 
  # filter(is.na(unk))
```

### 6. recode age


Since we have a few cases, we'll use `case_when()`, which is constructed like so, moving from specific to general cases because they are evaluated in order.

```{r, eval = FALSE}
case_when(condition_1 ~ case_1,
          condition_2 ~ case_2,
          condition_3 ~ case_3,
          TRUE ~ everything_else)
```

Here used for our age classes:
```{r, warning = FALSE}
# handle cases:
# P %>% pull(age) %>% unique()
P <- 
  P %>% 
  mutate(age = 
           case_when(age == "Less than 1 year" ~ 0,
                     age == "Open-ended age class" ~ 100,
                     TRUE ~ parse_number(age)))
```


### 7. calculate exposure
```{r}
a <- 0:10
a
lead(a)
lag(a)
```

```{r}
P <-
  P %>% 
  arrange(country, age, year) %>% 
  group_by(country, age) %>% 
  mutate(pop2 = lead(pop_hat)) %>% 
  ungroup() %>% 
  filter(!is.na(pop2)) %>% 
  mutate(expos = (pop2 + pop_hat) / 2)
```

### 8. bring it all together

```{r, message = FALSE}
E <- 
  read_excel(path = "Data/demo_pjan.xlsx",
             range = "A10:CZ510",
             na = ":") %>% 
  pivot_longer(#cols = 3:104,
               `Less than 1 year`:Unknown,
               names_to = "age",
               values_to = "pop") %>% 
  filter(!is.na(pop)) %>% 
  rename(year = TIME,
         country = `GEO/AGE`) %>% 
  group_by(country, year) %>% 
  mutate(unk = pop[age == "Unknown"]) %>% 
  filter(age != "Unknown") %>% 
  mutate(pop1 = pop + pop / sum(pop) * unk) %>% 
  ungroup() %>% 
  mutate(age = 
           case_when(age == "Less than 1 year" ~ 0,
                     age == "Open-ended age class" ~ 100,
                     TRUE ~ parse_number(age))) %>% 
  arrange(country, age, year) %>% 
  group_by(country, age) %>% 
  mutate(pop2 = lead(pop1)) %>% 
  ungroup() %>% 
  filter(!is.na(pop2)) %>% 
  mutate(expos = (pop2 + pop1) / 2)

```


## merge and calculate
```{r}

BE <-
  inner_join(B, 
             E, 
             by = c("country", "year","age")) %>% 
  select(country, year, age, births, births_hat, expos) %>% 
  mutate(fx = births_hat / expos)
```

```{r}
BE %>% 
  group_by(country, year) %>% 
  summarize(tfr = sum(fx),
            tfr_no_scale = sum(births / expos),
            mab_counts = sum((age + .5) * births_hat) / sum(births_hat),
            mab_fx = sum((age+5) * fx) / sum(fx))
```




