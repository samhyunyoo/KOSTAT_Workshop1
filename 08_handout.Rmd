---
title: | 
  | \includegraphics{logotip.pdf}
  |
  | KOSTAT-UNFPA Summer Seminar on Population
  | \vspace{1.5cm} \LARGE \emph{Workshop~1.~Demography in R}
  | \vspace{0.3cm} \huge \textbf{Day 8: Advanced processing and visualization}\vspace{0.6cm}
  | 
fontsize: 11pt
geometry: a4paper, twoside, left=2.5cm, right=2.5cm, top=2cm, bottom=2.8cm, headsep
  = 1.35cm, footskip = 1.6cm
output:
  pdf_document:
    number_sections: yes
  html_document2: default
  html_document:
    number_sections: yes
    toc: yes
  pdf_document2: default
  header-includes:
    - \usepackage{titling}
    - \usepackage{fancyhdr}
    - \pagestyle{fancy}
    - \fancyhead[LE]{\thepage~\qquad~KOSTAT-UNFPA Summer Seminar on Population}
    - \fancyhead[RE]{Workshop~1.~Demography in R}
    - \fancyhead[LO]{{Day 8: Advanced processing and visualization}}
    - \fancyhead[RO]{Tim Riffe\qquad~\thepage}
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\noindent\makebox[\textwidth][c]{
  \begin{minipage}[t]{0.8\textwidth}
    \centering
    \Large{Instructor: Tim Riffe \\ \texttt{tim.riffe@ehu.eus}}
   
    \vspace{.5cm}
    \Large{Assistants: \\ Jinyeon Jo: \texttt{jyjo43043@gmail.com} \\ Rustam Tursun-Zade: \texttt{rustam.tursunzade@gmail.com}}
  \end{minipage}
}


\vspace{0.8cm}
\begin{center}
\large{5 August 2022}
\end{center}
\vspace{0.8cm}


\tableofcontents

# Summary

In this lesson we try our hand at a spontaneously designed analytic exercise, making use of datasets chosen by participants in prior days. I suggested eight different *global* or *almost*-global datasets that we might tackle, and put it up to a vote. Here were the results:

![](friday_vote.png)
Based on this, I decided to use both World Population Prospects 2022 (@wpp2022) data and an extract from the 2019 Global Burden of Disease (@gbd2019). For the WPP we download a csv file manually, and for the GBD I made a selection from the online results tool, which generated 60 zip files, which I pre-process some in a supplement to this handout called `08_data_prep.pdf`. I shared the results of that processing in a file called `gbd-share.csv.gz`, which we read in below.

The objective of this exercise we to combine lifetables from WPP with prevalence estimates of various impairments from GBD and to use these to calculate different kinds of impairment and impairment-free life expectancy using the so-called Sullivan Method @sullivan1971single .

Most tools used have already been covered in the workshop, this is an agility exercise as much as anything, meant to drive home key concepts from the workshop. However, since this is a fresh exercise, I will reveal the bulk of the process, and indeed do most of the deriving as we go. With the clock ticking since we only have 1.5 hours. How did I choose to do things one way rather than another, and why do things in a particular order? This is important to convey because when you bring these tools to your own work, we sometimes get stuck, either because things don't work on the first try, or because we're unsure of process design aspects. Therefore, we will spend some time in this lesson charting out the steps in advance of actually writing them.

The code below is pasted from the session script (unlike the other handouts) due to its spontaneous nature.

## load dependencies
```{r, message = FALSE}
library(tidyverse)
library(vroom)
library(janitor)
library(countrycode)
```


## Read in WPP 2022 abridged lifetables

This file contains both countries, territories, and aggregates thereof, as well as different kinds of geocodes. We have abridged-age lifetables for males, females and the total population. The code below filters the file down to just those countries whose UN location ID is included the the `countrycode` package lookup table. This is just a cheap way to remove the regional aggregates. In the end, we'll use the ISO3 code for matching to GBD data anyway. Note we also divide out the lifetable radix from the `Lx` column, such that $e_0 = \sum L_x$. That just simplifies formulas for impairment-free life expectancy.
```{r}
wpp <- read_csv("Data/wpplt.zip",
                show_col_types = FALSE)
wpp <-
  wpp %>% 
  mutate(location = countrycode(LocID,
                                origin = "un",
                                destination = "country.name.en",
                                warn = FALSE)) %>% 
  filter(!is.na(location)) %>% 
  select(iso3 = ISO3_code,
         sex = Sex,
         year = Time,
         age = AgeGrpStart,
         mx, Lx, ex) %>% 
  mutate(Lx = Lx / 100000)

```

# Read in GBD

This was pre-processed in `06_data_prep.pdf`, have a look there if interested. Registration is free and easy for the GBD results tool.
```{r}
gbd <- read_csv("Data/gbd_share.csv.gz",
                show_col_types = FALSE)

gbd <-
  gbd %>% 
  mutate(iso3 = countrycode(location,
                            origin = "country.name.en",
                            destination = "iso3c")) %>% 
  arrange(location, measure, sex, year, age)

object.size(gbd) %>% print(units = "Mb")
```

## What measures do we have?

A few checks to decide what and how we calculate things. I see we have different severity breakdowns of a reduced set of potential impairments or deficiencies.
```{r}
gbd %>% pull(measure) %>% unique()
```

## Check sums
 
Is Anemia equal to the sum of mild and severe anemia? Let's do a check and see how this works so that we can do more intelligent calculations later

```{r}
gbd %>% 
  filter(iso3 == "AFG",
         year == 2019,
         sex == "Female",
         measure %in% c("Anemia", "Mild anemia", "Moderate anemia", "Severe anemia")) %>% 
  pivot_wider(names_from = measure, values_from = prev) %>% 
  mutate(check_sum = `Mild anemia` + `Moderate anemia` + `Severe anemia`) %>% 
  select(age, Anemia, check_sum)
```

Yes, the basic illness indicators are the sum of the severity breakdowns.

## examine some subsets
```{r, fig.width = 10, fig.height = 7}
gbd %>% 
  filter(iso3 %in% c("AUS","KOR","PER"),
         measure %in% c("Severe anemia", "Severe vision loss")) %>% 
  ggplot(mapping = aes(x = age,
                       y = prev,
                       color = sex,
                       alpha = year, 
                       group = interaction(year, sex))) +
  geom_line() +
  # new! gridded facetting, note prev measures are in rows
  # and locations in columns
  facet_grid(vars(measure), 
             vars(location)) +
  labs(y = "Anemia prevalence") +
  theme_minimal()
```


## Test merge

```{r}
wpp_test <- wpp %>% 
  filter(iso3 == "KOR")

gbd_test <- gbd %>% 
  filter(iso3 == "KOR")

# success
left_join(gbd_test,
          wpp_test,
          by = c("iso3","sex","year","age"))
```

## a little bit of lifetable rigor

Note, the lifetables close out at 100+, but the prevalence closes out at 95+, so we should do a little bit of adjustment to the lifetables to make these match.
```{r}
wpp <-
  wpp %>% 
  mutate(age = ifelse(age > 95, 95, age)) %>% 
  group_by(iso3, sex, year, age) %>% 
  summarize(mx = mx[1],
            Lx = sum(Lx),
            ex = ex[1],
            .groups = "drop")
```

Let's redo an example join to demonstrate the Sullivan method.
```{r}

wpp_test <-
  wpp %>% 
  filter(year == 2000,
         sex == "Female",
         iso3 == "KOR")

gbd_test <-
  gbd %>% 
  filter(year == 2000,
         sex == "Female",
         iso3 == "KOR",
         measure == "Severe anemia")
join_test <- 
left_join(gbd_test, 
          wpp_test, 
          by = c("iso3", "sex", "year", "age"))
```

## Demonstrate Sullivan

We have a survival step function, a red line for prevalence (conditional on survival), and and orange line showing the *lifetable burden* of the given condition. See how we divide out the interval width for $L_x$? That's just for the plot! We don't do it in the actual formula! 
```{r}
join_test %>% 
  ggplot(mapping = aes(x = age,
                       y = Lx / c(1,4,rep(5,19)))) +
  geom_step() +
  ylim(0,1) +
  geom_step(mapping = aes(x = age, 
                          y = prev),
            color = "red") +
  geom_step(mapping = aes(x = age,
                          y = Lx / c(1,4,rep(5,19)) * prev),
            color = "orange")
```

Actual HLE calculation is straightforward like so:
```{r}
join_test %>% 
  summarize(Anemia_LE = sum(Lx * prev),
            Anemia_free_LE = ex[age == 0] - Anemia_LE,
            LE = ex[age == 0])
```

## Hearing loss

Finally, we select some countries just for the sake of comparison, then calculate the various hearing-loss related expectancies.
```{r}
countrycode("Somalia", origin = "country.name.en", destination = "iso3c")

codes <- c("ESP","USA","DEU","KOR","BGD","SOM")
measures <- c("Hearing loss","Complete hearing loss","Mild hearing loss","Moderate hearing loss","Severe hearing loss")

# all(measures %in% gbd$measure)

hearing <-
gbd %>% 
  filter(year == 2019,
         iso3 %in% codes,
         measure %in% measures) %>% 
  left_join(wpp, by = c("iso3","year","sex","age")) %>% 
  group_by(iso3, sex, measure) %>% 
  summarize(hearing_loss_LE = sum(prev * Lx),
            better_hearing_LE = sum((1 - prev) * Lx),
            LE = sum(Lx),
            .groups = "drop")
```

## visualize

And finally we visualize this as a dot-plot, including some value-sorting of the country-rows using the handy `fct_reorder()` function (loads with `tidyverse`).
```{r}


hearing %>% 
  ggplot(mapping = aes(x = hearing_loss_LE, 
                       y = fct_reorder(iso3, hearing_loss_LE),
                       color = sex)) +
  facet_wrap(~measure, scales = "free_x") +
  geom_point()
```

Had there been more time we would have also sorted the panels (currently alphabetical!) according to severity.

# References
